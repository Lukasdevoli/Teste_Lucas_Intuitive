# Teste TÃ©cnico â€“ Intuitive Care

Este projeto implementa uma soluÃ§Ã£o completa de **Engenharia de Dados** e **Desenvolvimento Web**, abrangendo desde a coleta de dados pÃºblicos da **ANS (Web Scraping)** atÃ© a visualizaÃ§Ã£o em um **Dashboard interativo**.

**Autor:** Lucas  
**Data:** Fevereiro/2026

---

## ğŸš€ Como Executar o Projeto

### PrÃ©-requisitos
- Python 3.8+
- Navegador Web moderno

---

## 1. InstalaÃ§Ã£o das DependÃªncias

No terminal, na raiz do projeto:

```bash
pip install flask flask-cors pandas requests beautifulsoup4 openpyxl
```

---

## 2. ExecuÃ§Ã£o do Pipeline de Dados em Ordem (ETL)

Execute os scripts **na ordem abaixo** para baixar, processar e carregar os dados.

### Coleta e Processamento Inicial

```bash
python src/processor.py
```

> Baixa e extrai os dados trimestrais, gerando o arquivo `consolidado.csv`.

---

### Enriquecimento e TransformaÃ§Ã£o

```bash
python src/transformer.py
```

> Baixa o cadastro de operadoras, realiza o cruzamento (JOIN) e valida os dados.

---

### Carga no Banco de Dados

```bash
python src/database.py
```

> Cria o banco SQLite e importa os dados processados.

---

## 3. ExecuÃ§Ã£o da AplicaÃ§Ã£o

### Inicie o servidor Backend:

```bash
python src/api/app.py
```

### Frontend

Abra o arquivo abaixo diretamente no navegador:

```
src/frontend/index.html
```

---

## ğŸ› ï¸ DecisÃµes TÃ©cnicas e Trade-offs

Conforme solicitado no teste, abaixo estÃ£o as justificativas para as escolhas tÃ©cnicas adotadas, priorizando **simplicidade e eficiÃªncia (PrincÃ­pio KISS)**.

---

### 1ï¸âƒ£ Web Scraping & ETL

**Trade-off:** Processamento em MemÃ³ria (Pandas) vs Streaming  

**DecisÃ£o:** Uso de **Pandas com processamento em memÃ³ria**

**Justificativa:**  
O volume de dados dos Ãºltimos 3 trimestres cabe confortavelmente na memÃ³ria RAM de mÃ¡quinas modernas. O Pandas acelera o desenvolvimento e oferece robustez no tratamento de dados, como:
- Encoding `latin1`
- RemoÃ§Ã£o de caracteres especiais  

Essas operaÃ§Ãµes seriam mais complexas em um modelo de processamento linha a linha (streaming).

**EstratÃ©gia de Join e Dados Incompletos:**

**Desafio:** InconsistÃªncia na formataÃ§Ã£o da chave RegistroANS (ex: `3456.0` vs `3456`) e indisponibilidade momentÃ¢nea do site da ANS.

**SoluÃ§Ã£o:** ImplementaÃ§Ã£o de limpeza matemÃ¡tica nas chaves antes do cruzamento e uso de Left Join. Registros sem correspondÃªncia no cadastro sÃ£o marcados como "DESCONHECIDO" para preservar os valores contÃ¡beis totais, priorizando a integridade financeira sobre a completude cadastral.

---

### 2ï¸âƒ£ Banco de Dados

**Trade-off:** SQLite vs MySQL/PostgreSQL  

**DecisÃ£o:** **SQLite**

**Justificativa:**  
- Elimina configuraÃ§Ã£o de servidor, Docker ou credenciais  
- Banco em arquivo Ãºnico (`.db`)  
- Portabilidade total para o avaliador  
- SQL padrÃ£o ANSI, permitindo migraÃ§Ã£o fÃ¡cil para PostgreSQL em produÃ§Ã£o  

---

### 3ï¸âƒ£ Backend (API)

**Trade-off:** Flask vs FastAPI  

**DecisÃ£o:** **Flask**

**Justificativa:**  
Para um microsserviÃ§o **read-heavy**, o Flask oferece:
- ConfiguraÃ§Ã£o mÃ­nima  
- Baixa curva de aprendizado  
- Simplicidade  

A paginaÃ§Ã£o Ã© feita via `LIMIT / OFFSET` diretamente no SQL, garantindo respostas leves em JSON para o frontend.

---

### 4ï¸âƒ£ Frontend

**Trade-off:** Vue.js (CDN) vs Vue CLI / Vite  

**DecisÃ£o:** **Vue.js via CDN (HTML Ãºnico)**

**Justificativa:**  
- Evita dependÃªncia de Node.js / NPM  
- Sem etapa de build  
- Basta abrir o arquivo HTML para funcionar  

O frontend Ã© **serverless em termos de infraestrutura local**.

---

## ğŸ“„ DocumentaÃ§Ã£o da API
A API disponibiliza os seguintes endpoints:

- GET / - Status da API.
- GET /api/estatisticas - Retorna KPIs gerais (Total, MÃ©dia, Top 5).
- GET /api/operadoras - Listagem paginada com busca textual.
- Params: page, limit, search.
- GET /api/operadoras/<id>/despesas - HistÃ³rico detalhado de despesas de uma operadora.

---

## ğŸ“‚ Estrutura de Arquivos

```text
Teste_Lucas_Intuitive/
â”‚
â”œâ”€â”€ data/                      # Camada de Dados (Data Lakehouse Local)
â”‚   â”œâ”€â”€ raw/                   # Arquivos brutos baixados da ANS (ZIPs, CSVs)
â”‚   â”œâ”€â”€ processed/             # Dados tratados e consolidados
â”‚   â””â”€â”€ intuitive_care.db      # Banco de Dados SQLite
â”‚
â”œâ”€â”€ src/                       # CÃ³digo Fonte
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ app.py             # Servidor Backend (Flask)
â”‚   â”œâ”€â”€ frontend/
â”‚   â”‚   â””â”€â”€ index.html         # Interface do UsuÃ¡rio (Vue.js + Bootstrap)
â”‚   â”œâ”€â”€ scraper.py             # Coleta de dados (Web Scraping)
â”‚   â”œâ”€â”€ processor.py           # ExtraÃ§Ã£o e NormalizaÃ§Ã£o (ETL - Fase 1)
â”‚   â”œâ”€â”€ transformer.py         # Enriquecimento e ValidaÃ§Ã£o (ETL - Fase 2)
â”‚   â””â”€â”€ database.py            # PersistÃªncia e Modelagem (SQL)
â”‚
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ queries.sql            # Scripts DDL e Queries AnalÃ­ticas solicitadas
â”‚
â”œâ”€â”€ requirements.txt           # DependÃªncias do Python
â””â”€â”€ README.md                  # DocumentaÃ§Ã£o do Projeto
```
